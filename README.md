# ORB-SLAM3 with Ground Map Creation

## 1. Description
The purpose of this software is to use SLAM with RGB-D in order to create a map of its surroundings, with a possibility to generate a map of the ground only using DETR image segmentation, all in real-time.

It is mainly based on [ORB-SLAM3](https://github.com/UZ-SLAMLab/ORB_SLAM3), and we took a similar approach of generating the map from [DS-SLAM](https://github.com/ivipsourcecode/DS-SLAM) using [OctoMap](https://octomap.github.io/). The image segmentation for floor detection is based on [DETR: End-to-End Object Detection with Transformers](https://github.com/facebookresearch/detr). ZED cameras and SVO pre-recorded video were used for demonstration. 

We use ROS with Python and C++ to combine different modules easily.


## 2. Prerequisites
We tested the software on **Ubuntu 18.04** with a computer running on **Intel i7**, **16 GB of RAM**, and **RTX 2070**.


### 2.1. ORB-SLAM3
Install all ORB-SLAM3 prerequisites [ORB-SLAM3](https://github.com/UZ-SLAMLab/ORB_SLAM3)

**IMPORTANT NOTE:** Download **Eigen3.2.x** and **OpenCV3.x** instead of the newer versions. Newer versions may have compability issues. 

We used the binary of the ORB Vocabulary instead of the text for faster execution startup. Unzip the `ORBvoc.zip` in the `Vocabulary` directory, and name it `ORBvoc.bin` 


### 2.2. ROS
Tested on ROS-MELODIC. 

For image segmentation, we need **Python3**. Since ROS' default python is Python2, we need to add support to Python3.
Follow this article: [How to setup ROS with Python3](https://medium.com/@beta_b0t/how-to-setup-ros-with-python-3-44a69ca36674)


### 2.3. CUDA, cuDNN, and TensorRT
Tested on CUDA 11.2, cuDNN 8.1.1, TensorRT 7.2.2.
Follow this artice: [Setting up your NVIDIA environment](https://blog.jeremarc.com/setup/nvidia/cuda/linux/2020/09/19/nvidia-cuda-setup.html)


### 2.4.OctoMap 
Used OctoMap for map generation using ROS and visualized using RVIZ.
2 ROS dependencies are needed: [octomap_mapping](https://github.com/OctoMap/octomap_mapping) and [octomap_rviz_plugins](https://github.com/OctoMap/octomap_rviz_plugins) 
We suggest that the installation path of octomap_mapping and octomap_rviz_plugins to be catkin_ws/src. 
Add `#define COLOR_OCTOMAP_SERVER` into the `OctomapServer.h` at the folder of `octomap_mapping/octomap_server/include/octomap_server` 


### 2.5. ZED (Optional)
Tested used ZED cameras and ZED SVO videos. We used a ROS wrapper on top of ZED SDK in order to easily subscribe to topic create by ZED-Wrapper to get the images and their data. 
We used the RGB-D images generated by the ZED stereo cameras.

Note that it is possible to use other types of cameras as long as it is possible for it to publish the image on a ROS topic. 
Follow this article: [ZED Installation](https://www.stereolabs.com/docs/ros/)


## 3. Building
Clone the repository

We provide a script `build.sh` to build *ORB-SLAM3*. Please make sure you have installed all required dependencies. Execute:
```
cd ORB_SLAM3
chmod +x build.sh
./build.sh
```

This will create **libORB_SLAM3.so**  at *lib* folder and the executables in *Examples* folder.

Then we need to build the ros wrapper of ORB-SLAM3 and ImageSegmentation by executing:
```
chmod +x build_ros.sh
./build_ros.sh
```
This targets the directory `Examples/ROS/ORB_SLAM3` and `Examples/ROS/pointcloud_segmentation`

Note: In `build_ros.sh`, you may have to change the path of Python3 paths (`PYTHON_EXECUTABLE`, `PYTHON_INCLUDE_DIR`, `PYTHON_LIBRARY`) mentioned in the article [How to setup ROS with Python3](https://medium.com/@beta_b0t/how-to-setup-ros-with-python-3-44a69ca36674)


## 4. Running
In order to run the software:
1. Run `roscore` in one terminal

2. In another terminal
```
chmod +x slam_rgbd_zed_ros.sh
./slam_rgbd_zed_ros.sh zed

```
The first argument is the camera model, with the resolution (default is HD) 
Possible arguments are: `zed` `zed-vga` `zed2` `zedm`
This executes a ROS launch file `slam_rgbd_zed.launch` with different parameters depending on the ZED camera model.
It runs the ROS Nodes: ORB-SLAM3, ImageSegmentation, OctoMap, Transformations, and RVIZ.

In RVIZ, add the `ColorOccupancyGrid` in `octomap_rviz_plugins`, and subscribe to the topic `/octomap_full`. You should see the colored octomap being contructed in real-time. You can display the color of the cell based on the original color, depth, and probablity in `Voxel Coloring`.

3. In another terminal 
```
chmod +x publish_images_zed.sh
./publish_images_zed.sh zed  # for a connected zed camera with live images
./publish_images_zed.sh zed2 svo_file_path.svo  # for an SVO video recorded with a ZED2 camera  
```
This executes ZED Wrapper that publishes images from SVO files or from live ZED camera

Possible arguments: 
1. First argument is the camera model: `zed` `zed-vga` `zed2` `zedm`
2. Second argument is the SVO file path, if not provided, images from the connected camera will be published


## 5. How it works
ROS is used to create multiple nodes


### 5.1. ZED
Responsible for taking images from either a camera or an SVO video and publishing the images to a ROS topic.
The ZED camera configurations and parameters (`.yaml` files) are located in `zed/params/`


### 5.2. Segmentation
Responsible for segmenting the RGB images from ZED, and creating a mask based on the segmentations. Then, publishes the mask to a new ROS topic.
Note that the current implmentation creates a mask of the ground. This can be easily modified to create a mask of people, etc...
The code is located in `Examples/ROS/pointcloud_segmentation`

### 5.3. SLAM + PointCloud 
1. Runs the official ORB-SLAM3 based on RGB-D input images
2. Additional PointCloudMapper responsible for creating and publishing the pointclouds.
  How it works:
   1. Get the RGB-D, KeyFrame, CameraPose, and Sequence number from ORB-SLAM3
   2. Subscribe to the mask ROS topic, and wait for a mask with the same sequence number to be received
   3. Create a pointcloud and a transformation matrix (camera to world) based on all the previous data
   4. Publish the pointcloud and transformation matrix to 2 new ROS topics
      This code is located in `src/PointCloudMapping.cc`


### 5.4. Transformation
Responsible for handling transformations from the camera to robot, and from the camera to world.
We have 3 frames in the current implementation:
1. `/map` the main frame of reference
2. `/cameraToRobot` the frame which transforms the camera to the robot body (depends on the position and orientation of the camera on the robot)
3. `/pointCloudFrame` the frame of the pointcloud, based on the translation and rotation of the camera
Note that frame 3. is a child of frame 2. which is a child of frame 1. 
This code is located in `src/PointCloudMapping.cc`
This transformation is applied on the pointcloud handled by OctoMap

**Note:** the `/cameraToRobot` depends on the position and orientation of the camera with respect to the robot. You may need to change this accordingly. This is located in the launch file `/Examples/ROS/ORB_SLAM3/launch/transform.launch`


### 5.5. OctoMap
Responsible for generating an octomap based on the previously published point clouds and transformation matrices.

Note about **resolution** of PointCloud and OctoMap: you can change the resolution of the published pointcloud and octomap by modifying the values in `/Examples/ROS/ORB_SLAM3/launch/octomap.launch` and the value of `PointCloudMapping.Resolution` in the zed configuration `.yaml` files in `/zed/params`.
Make sure that both pointcloud and octomap have the same resolution.


### 5.6. RVIZ
Responsible for visualization of the pointclouds and the octomap. 


## 6. Significant files
- For ORB-SLAM3: 
  - `/src/System.cc` 
  - `/src/Tracking.cc`
  - `/Examples/ROS/ORB_SLAM3/src/ros_rgbd.cc`
- For PointCloud, Segmentation and Transformations:
  - `/src/PointCloudMapping.cc`
  - `/Examples/ROS/pointcloud_segmentation/src/image_segmentation.py`
  - `/Examples/ROS/ORB_SLAM3/launch/transform.launch`
- For ZED configurations:
  - `/zed/params`
