# ORB-SLAM3 with Ground Map Creation

## Description
The purpose of this software is to use SLAM with RGB-D in order to create a map of its surroundings, with a possibility to generate a map of the ground only using DETR image segmentation, all in real-time.
It is mainly based on [ORB-SLAM3](https://github.com/UZ-SLAMLab/ORB_SLAM3), and we took a similar approach of generating the map from [DS-SLAM](https://github.com/ivipsourcecode/DS-SLAM) using [OctoMap](https://octomap.github.io/). The image segmentation for floor detection is based on [DETR: End-to-End Object Detection with Transformers](https://github.com/facebookresearch/detr). ZED cameras and SVO pre-recorded video were used for demonstration. 

We use ROS with Python and C++ to combine different modules easily.


## Prerequisites
We tested the software on **Ubuntu 18.04** with a computer running on **Intel i7**, **16 GB of RAM**, and **RTX 2070**.

### ORB-SLAM3
Install ORB-SLAM3 with all its prerequisistes and make sure it is building and running successfully
Also download the binary of the ORB Vocabulary for faster execution on startup and add it the `Vocabulary` directory
[Binary Orb Vocabulary](https://drive.google.com/file/d/16D3mZeh73pkOFvlpngQVavHrFKeIiRX3/view?usp=sharing) 

### ROS
Tested on ROS-MELODIC 
For image segmentation, we need **Python3**. Since ROS' default python is Python2, we need to add support to Python3
Follow this article: [How to setup ROS with Python3](https://medium.com/@beta_b0t/how-to-setup-ros-with-python-3-44a69ca36674)

### CUDA, cuDNN, and TensorRT
Tested on CUDA 11.2, cuDNN 8.1.1, TensorRT 7.2.2
Follow this artice: [Setting up your NVIDIA environment](https://blog.jeremarc.com/setup/nvidia/cuda/linux/2020/09/19/nvidia-cuda-setup.html)

### ZED (Optional)
Tested used ZED cameras and ZED SVO videos. We used a ROS wrapper on top of ZED SDK in order to easily subscribe to topic create by ZED-Wrapper to get the images and their data. 
We used the RGB-D images generated by the ZED stereo cameras.
Note that it is possible to use other types of cameras as long as it is possible for it to publish the image on a ROS topic. 
Follow this article: [ZED Installation](https://www.stereolabs.com/docs/ros/)

### OctoMap 
Used OctoMap for map generation using ROS and visualized using RVIZ
2 ROS dependencies are needed: [octomap_mapping](https://github.com/OctoMap/octomap_mapping) and [octomap_rviz_plugins](https://github.com/OctoMap/octomap_rviz_plugins) 
We suggest that the installation path of octomap_mapping and octomap_rviz_plugins to be catkin_ws/src. 
Add `#define COLOR_OCTOMAP_SERVER` into the `OctomapServer.h` at the folder of `octomap_mapping/octomap_server/include/octomap_server` 


## Building
Clone the repository

We provide a script `build.sh` to build *ORB-SLAM3*. Please make sure you have installed all required dependencies. Execute:
```
cd ORB_SLAM3
chmod +x build.sh
./build.sh
```

This will create **libORB_SLAM3.so**  at *lib* folder and the executables in *Examples* folder.

Then we need to build the ros wrapper of ORB-SLAM3 by executing:
```
chmod +x build_ros.sh
./build_ros.sh
```

## Running
In order to run the software:
1. Run `roscore` in one terminal

2. In another terminal
```
chmod +x slam_rgbd_zed_ros.sh
./slam_rgbd_zed_ros.sh zed

```
The first argument is the camera model, with the resolution (default is HD) 
Possible arguments are: `zed` `zed-vga` `zed2` `zedm`
This executes a ROS launch file `slam_rgbd_zed.launch` with different parameters depending on the ZED camera model.
It runs the ROS Nodes: ORB-SLAM3, ImageSegmentation, OctoMap, Transformations, and RVIZ.

3. In another terminal 
```
chmod +x publish_images_zed.sh
./publish_images_zed.sh zed  # for a connected zed camera with live images
./publish_images_zed.sh zed2 svo_file_path.svo  # for an SVO video recorded with a ZED2 camera  
```
This executes ZED Wrapper that publishes images from SVO files or from live ZED camera

Possible arguments: 
1. First argument is the camera model: `zed` `zed-vga` `zed2` `zedm`
2. Second argument is the SVO file path, if not provided, images from the connected camera will be published


## How it works
ROS is used to create multiple nodes

### Node 1. ZED
Responsible for taking images from either a camera or an SVO video and publising the images to a ROS topic.

### Node 2. Segmentation
Responsible for segmenting the RGB images from ZED, and creating a mask based on the segmentations. Then, publishes the mask to a new ROS topic.
Note that the current implmentation creates a mask of the ground. This can be easily modified to create a mask of people, etc...

### Node 3. SLAM
1. Runs the official ORB-SLAM3 based on RGB-D input images
2. Additional PointCloudMapper responsible for creating and publishing the pointclouds
   1. Get the RGB-D, KeyFrame, CameraPose, and Sequence number from ORB-SLAM3
   2. Subscribe to the mask ROS topic, and wait for a mask with the same sequence number to be received
   3. Create a pointcloud and a transformation matrix (camera to world) based on all the previous data
   4. Publish the pointcloud and transformation matrix to 2 new ROS topics

### Node 4. Transformation
Responsible for handling transformations from the camera to robot, and from the camera to world.
We have 3 frames in the current implementation:
1. `/map` the main frame of reference
2. `/cameraToRobot` the frame which transforms the camera to the robot body (depends on the position and orientation of the camera on the robot)
3. `/pointCloudFrame` the frame of the pointcloud, based on the translation and rotation of the camera
Note that frame 3. is a child of frame 2. which is a child of frame 1. 
This transformation is applied on the pointcloud handled by OctoMap

### Node 5. OctoMap
Responsible for generating an octomap based on the previously published point clouds and transformation matrices.

 
